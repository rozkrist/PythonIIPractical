{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c1db6d",
   "metadata": {},
   "source": [
    "Cross-Database Data Integration and Analysis Project - SPOTIFY "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652639c0",
   "metadata": {},
   "source": [
    "1. Data Extraction:\n",
    "   - Extract data from a SQL database containing sales transactions, a MongoDB database with customer reviews, and a Neo4j graph database storing social network relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6f661",
   "metadata": {},
   "source": [
    "Spotify Api creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0310f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = \"a1a8dafef9614bb68dcc729cd14a3399\"\n",
    "CLIENT_SECRET = \"8ad8630c3bc04d47ab3839cf106cd324\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfebcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b6fd9",
   "metadata": {},
   "source": [
    "2. Data Transformation:\n",
    "   - Use PySpark to clean and transform the extracted data into a unified format suitable for analysis.\n",
    "   - Handle data type conversions, null values, and inconsistencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f3a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd595d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abd6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf8da5a",
   "metadata": {},
   "source": [
    "3. Data Integration:\n",
    "   - Combine the transformed data from the three databases into a common storage or data frame structure. (in Python â€“ examples, in Pandas or you can store all this data locally in the files)\n",
    "   - Design a schema that accommodates the heterogeneous data types and structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39859dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54195a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ff705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf75b266",
   "metadata": {},
   "source": [
    "4. Data Analysis:\n",
    "   - Perform exploratory data analysis (EDA) to understand the characteristics of the integrated dataset (average values, standard deviation, etc.).\n",
    "   - Using Time Series, Linear regression or any other approach  to identify patterns, trends, and correlations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46393b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d24e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a45cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd1eda0",
   "metadata": {},
   "source": [
    "5. Graph Analysis:\n",
    "   - Extract relevant data from the Neo4j graph database to analyse social network influences on customer behaviours.\n",
    "   - Identify key influencers, communities, and connections \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b80c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acbc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e9d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d268162",
   "metadata": {},
   "source": [
    "6. Data Visualization:\n",
    "   - Create interactive visualizations using libraries like Matplotlib, Plotly, or Seaborn.\n",
    "   - Visualize sales trends, customer sentiment distribution, and social network graphs to present findings effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879c4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827297bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae52ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "943a5673",
   "metadata": {},
   "source": [
    "7. Insights and Reporting:\n",
    "   - Summarize the insights gained from the data analysis, including correlations between social connections, sentiments, and sales performance.\n",
    "   - Prepare a detailed report and presentation for stakeholders, highlighting actionable recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d9fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9507c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f2e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "854d6e05",
   "metadata": {},
   "source": [
    "8. Performance Optimization:\n",
    "   - Optimize data processing tasks in PySpark for improved performance, considering data partitioning, caching, and parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd891f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2b7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9070173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feaeef3f",
   "metadata": {},
   "source": [
    "Additional:\n",
    "9. Sentiment Analysis:\n",
    "   - Apply natural language processing techniques using PySpark to the customer reviews from MongoDB.\n",
    "   - Perform sentiment analysis to categorize reviews as positive, negative, or neutral.\n",
    "   - Correlate sentiment with sales data to understand the impact on business performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50857f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
